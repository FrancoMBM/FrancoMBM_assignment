{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy as sp\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part other models will be used in order to see if greater accuracy is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_white = pd.read_csv(\"winequality-white.csv\", sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding target variable\n",
    "\n",
    "Creating dummy variables and separate each category into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_df_white.iloc[:,:-1]\n",
    "y = raw_df_white['quality']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder()\n",
    "y = onehotencoder.fit_transform(y).toarray()\n",
    "y = pd.DataFrame(y)\n",
    "y.columns = ['3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_white, X_test_white, y_train_white, y_test_white = cross_validation.train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3918.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>0.296580</td>\n",
       "      <td>0.456611</td>\n",
       "      <td>0.177897</td>\n",
       "      <td>0.036243</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.052919</td>\n",
       "      <td>0.166661</td>\n",
       "      <td>0.456808</td>\n",
       "      <td>0.498177</td>\n",
       "      <td>0.382475</td>\n",
       "      <td>0.186918</td>\n",
       "      <td>0.035705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 3            4            5            6            7  \\\n",
       "count  3918.000000  3918.000000  3918.000000  3918.000000  3918.000000   \n",
       "mean      0.002808     0.028586     0.296580     0.456611     0.177897   \n",
       "std       0.052919     0.166661     0.456808     0.498177     0.382475   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 8            9  \n",
       "count  3918.000000  3918.000000  \n",
       "mean      0.036243     0.001276  \n",
       "std       0.186918     0.035705  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_train_white.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing feature scaling on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler =  MinMaxScaler()\n",
    "#scaler = Normalizer()\n",
    "X_train_white = scaler.fit(X_train_white).transform(X_train_white)\n",
    "X_test_white = scaler.fit(X_test_white).transform(X_test_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN\n",
    "\n",
    "Performing Artificial Neural Networks. \n",
    "Instanciating the model adding layers and training the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3918/3918 [==============================] - 2s 458us/step - loss: 1.3815 - acc: 0.4505\n",
      "Epoch 2/100\n",
      "3918/3918 [==============================] - 1s 304us/step - loss: 1.2477 - acc: 0.4592\n",
      "Epoch 3/100\n",
      "3918/3918 [==============================] - 1s 277us/step - loss: 1.1895 - acc: 0.4806\n",
      "Epoch 4/100\n",
      "3918/3918 [==============================] - 1s 282us/step - loss: 1.1281 - acc: 0.5110\n",
      "Epoch 5/100\n",
      "3918/3918 [==============================] - 1s 286us/step - loss: 1.0932 - acc: 0.5120\n",
      "Epoch 6/100\n",
      "3918/3918 [==============================] - 1s 354us/step - loss: 1.0794 - acc: 0.5253\n",
      "Epoch 7/100\n",
      "3918/3918 [==============================] - 1s 347us/step - loss: 1.0659 - acc: 0.5401\n",
      "Epoch 8/100\n",
      "3918/3918 [==============================] - 1s 361us/step - loss: 1.0545 - acc: 0.5426\n",
      "Epoch 9/100\n",
      "3918/3918 [==============================] - 1s 346us/step - loss: 1.0474 - acc: 0.5465\n",
      "Epoch 10/100\n",
      "3918/3918 [==============================] - 1s 342us/step - loss: 1.0395 - acc: 0.5480\n",
      "Epoch 11/100\n",
      "3918/3918 [==============================] - 2s 388us/step - loss: 1.0330 - acc: 0.5510\n",
      "Epoch 12/100\n",
      "3918/3918 [==============================] - 1s 356us/step - loss: 1.0249 - acc: 0.5551\n",
      "Epoch 13/100\n",
      "3918/3918 [==============================] - 2s 407us/step - loss: 1.0257 - acc: 0.5666\n",
      "Epoch 14/100\n",
      "3918/3918 [==============================] - 1s 365us/step - loss: 1.0261 - acc: 0.5628\n",
      "Epoch 15/100\n",
      "3918/3918 [==============================] - 1s 337us/step - loss: 1.0217 - acc: 0.5641\n",
      "Epoch 16/100\n",
      "3918/3918 [==============================] - 1s 341us/step - loss: 1.0209 - acc: 0.5610\n",
      "Epoch 17/100\n",
      "3918/3918 [==============================] - 1s 353us/step - loss: 1.0154 - acc: 0.5630\n",
      "Epoch 18/100\n",
      "3918/3918 [==============================] - 1s 344us/step - loss: 1.0138 - acc: 0.5625\n",
      "Epoch 19/100\n",
      "3918/3918 [==============================] - 1s 352us/step - loss: 1.0134 - acc: 0.5676\n",
      "Epoch 20/100\n",
      "3918/3918 [==============================] - 1s 351us/step - loss: 1.0139 - acc: 0.5661\n",
      "Epoch 21/100\n",
      "3918/3918 [==============================] - 1s 352us/step - loss: 1.0108 - acc: 0.5661\n",
      "Epoch 22/100\n",
      "3918/3918 [==============================] - 1s 360us/step - loss: 1.0071 - acc: 0.5694\n",
      "Epoch 23/100\n",
      "3918/3918 [==============================] - 1s 345us/step - loss: 1.0014 - acc: 0.5661\n",
      "Epoch 24/100\n",
      "3918/3918 [==============================] - 1s 350us/step - loss: 1.0034 - acc: 0.5758\n",
      "Epoch 25/100\n",
      "3918/3918 [==============================] - 1s 352us/step - loss: 0.9990 - acc: 0.5725\n",
      "Epoch 26/100\n",
      "3918/3918 [==============================] - 2s 397us/step - loss: 0.9977 - acc: 0.5817 1s -\n",
      "Epoch 27/100\n",
      "3918/3918 [==============================] - 1s 353us/step - loss: 0.9974 - acc: 0.5781\n",
      "Epoch 28/100\n",
      "3918/3918 [==============================] - 1s 346us/step - loss: 0.9975 - acc: 0.5763\n",
      "Epoch 29/100\n",
      "3918/3918 [==============================] - 1s 346us/step - loss: 0.9909 - acc: 0.5830\n",
      "Epoch 30/100\n",
      "3918/3918 [==============================] - 1s 351us/step - loss: 0.9923 - acc: 0.5814\n",
      "Epoch 31/100\n",
      "3918/3918 [==============================] - 1s 347us/step - loss: 0.9913 - acc: 0.5789\n",
      "Epoch 32/100\n",
      "3918/3918 [==============================] - 1s 343us/step - loss: 0.9927 - acc: 0.5786\n",
      "Epoch 33/100\n",
      "3918/3918 [==============================] - 1s 347us/step - loss: 0.9847 - acc: 0.5827\n",
      "Epoch 34/100\n",
      "3918/3918 [==============================] - 1s 349us/step - loss: 0.9866 - acc: 0.5786\n",
      "Epoch 35/100\n",
      "3918/3918 [==============================] - 1s 352us/step - loss: 0.9869 - acc: 0.5776\n",
      "Epoch 36/100\n",
      "3918/3918 [==============================] - 1s 353us/step - loss: 0.9845 - acc: 0.5847\n",
      "Epoch 37/100\n",
      "3918/3918 [==============================] - 1s 364us/step - loss: 0.9862 - acc: 0.5763\n",
      "Epoch 38/100\n",
      "3918/3918 [==============================] - 1s 372us/step - loss: 0.9822 - acc: 0.5799\n",
      "Epoch 39/100\n",
      "3918/3918 [==============================] - 2s 527us/step - loss: 0.9788 - acc: 0.5842\n",
      "Epoch 40/100\n",
      "3918/3918 [==============================] - 2s 439us/step - loss: 0.9775 - acc: 0.5827\n",
      "Epoch 41/100\n",
      "3918/3918 [==============================] - 1s 381us/step - loss: 0.9839 - acc: 0.5837\n",
      "Epoch 42/100\n",
      "3918/3918 [==============================] - 2s 395us/step - loss: 0.9799 - acc: 0.5832\n",
      "Epoch 43/100\n",
      "3918/3918 [==============================] - 2s 392us/step - loss: 0.9781 - acc: 0.5906\n",
      "Epoch 44/100\n",
      "3918/3918 [==============================] - 1s 366us/step - loss: 0.9744 - acc: 0.5949\n",
      "Epoch 45/100\n",
      "3918/3918 [==============================] - 1s 378us/step - loss: 0.9709 - acc: 0.5947\n",
      "Epoch 46/100\n",
      "3918/3918 [==============================] - 1s 374us/step - loss: 0.9734 - acc: 0.5870\n",
      "Epoch 47/100\n",
      "3918/3918 [==============================] - 1s 374us/step - loss: 0.9712 - acc: 0.5891\n",
      "Epoch 48/100\n",
      "3918/3918 [==============================] - 2s 399us/step - loss: 0.9672 - acc: 0.5898\n",
      "Epoch 49/100\n",
      "3918/3918 [==============================] - 1s 359us/step - loss: 0.9643 - acc: 0.5926\n",
      "Epoch 50/100\n",
      "3918/3918 [==============================] - 1s 365us/step - loss: 0.9653 - acc: 0.5924\n",
      "Epoch 51/100\n",
      "3918/3918 [==============================] - 1s 364us/step - loss: 0.9611 - acc: 0.5947\n",
      "Epoch 52/100\n",
      "3918/3918 [==============================] - 1s 355us/step - loss: 0.9600 - acc: 0.5942\n",
      "Epoch 53/100\n",
      "3918/3918 [==============================] - 1s 366us/step - loss: 0.9583 - acc: 0.5972\n",
      "Epoch 54/100\n",
      "3918/3918 [==============================] - 2s 405us/step - loss: 0.9604 - acc: 0.5965\n",
      "Epoch 55/100\n",
      "3918/3918 [==============================] - 2s 448us/step - loss: 0.9549 - acc: 0.5965\n",
      "Epoch 56/100\n",
      "3918/3918 [==============================] - 2s 400us/step - loss: 0.9570 - acc: 0.6018\n",
      "Epoch 57/100\n",
      "3918/3918 [==============================] - 2s 400us/step - loss: 0.9556 - acc: 0.5998\n",
      "Epoch 58/100\n",
      "3918/3918 [==============================] - 2s 389us/step - loss: 0.9509 - acc: 0.5947\n",
      "Epoch 59/100\n",
      "3918/3918 [==============================] - 2s 387us/step - loss: 0.9527 - acc: 0.5983\n",
      "Epoch 60/100\n",
      "3918/3918 [==============================] - 2s 422us/step - loss: 0.9516 - acc: 0.6039\n",
      "Epoch 61/100\n",
      "3918/3918 [==============================] - 2s 413us/step - loss: 0.9476 - acc: 0.6016\n",
      "Epoch 62/100\n",
      "3918/3918 [==============================] - 1s 358us/step - loss: 0.9474 - acc: 0.6041\n",
      "Epoch 63/100\n",
      "3918/3918 [==============================] - 1s 382us/step - loss: 0.9495 - acc: 0.6036\n",
      "Epoch 64/100\n",
      "3918/3918 [==============================] - 1s 363us/step - loss: 0.9500 - acc: 0.6036\n",
      "Epoch 65/100\n",
      "3918/3918 [==============================] - 1s 367us/step - loss: 0.9422 - acc: 0.6123\n",
      "Epoch 66/100\n",
      "3918/3918 [==============================] - 1s 371us/step - loss: 0.9428 - acc: 0.6067\n",
      "Epoch 67/100\n",
      "3918/3918 [==============================] - 1s 369us/step - loss: 0.9448 - acc: 0.6108\n",
      "Epoch 68/100\n",
      "3918/3918 [==============================] - 1s 369us/step - loss: 0.9468 - acc: 0.6041\n",
      "Epoch 69/100\n",
      "3918/3918 [==============================] - 1s 368us/step - loss: 0.9478 - acc: 0.6075\n",
      "Epoch 70/100\n",
      "3918/3918 [==============================] - 1s 373us/step - loss: 0.9379 - acc: 0.6113\n",
      "Epoch 71/100\n",
      "3918/3918 [==============================] - 1s 371us/step - loss: 0.9405 - acc: 0.6131\n",
      "Epoch 72/100\n",
      "3918/3918 [==============================] - 1s 380us/step - loss: 0.9317 - acc: 0.6166\n",
      "Epoch 73/100\n",
      "3918/3918 [==============================] - 1s 379us/step - loss: 0.9354 - acc: 0.6149\n",
      "Epoch 74/100\n",
      "3918/3918 [==============================] - 1s 361us/step - loss: 0.9316 - acc: 0.6128\n",
      "Epoch 75/100\n",
      "3918/3918 [==============================] - 2s 394us/step - loss: 0.9339 - acc: 0.6095\n",
      "Epoch 76/100\n",
      "3918/3918 [==============================] - 2s 399us/step - loss: 0.9333 - acc: 0.6169\n",
      "Epoch 77/100\n",
      "3918/3918 [==============================] - 2s 441us/step - loss: 0.9326 - acc: 0.6164\n",
      "Epoch 78/100\n",
      "3918/3918 [==============================] - 2s 413us/step - loss: 0.9334 - acc: 0.6062\n",
      "Epoch 79/100\n",
      "3918/3918 [==============================] - 2s 549us/step - loss: 0.9345 - acc: 0.6136\n",
      "Epoch 80/100\n",
      "3918/3918 [==============================] - 2s 402us/step - loss: 0.9279 - acc: 0.6141\n",
      "Epoch 81/100\n",
      "3918/3918 [==============================] - 2s 412us/step - loss: 0.9264 - acc: 0.6238\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3918/3918 [==============================] - 2s 408us/step - loss: 0.9279 - acc: 0.6133\n",
      "Epoch 83/100\n",
      "3918/3918 [==============================] - 2s 394us/step - loss: 0.9315 - acc: 0.6276\n",
      "Epoch 84/100\n",
      "3918/3918 [==============================] - 2s 438us/step - loss: 0.9274 - acc: 0.6220\n",
      "Epoch 85/100\n",
      "3918/3918 [==============================] - 2s 386us/step - loss: 0.9278 - acc: 0.6246\n",
      "Epoch 86/100\n",
      "3918/3918 [==============================] - 2s 395us/step - loss: 0.9250 - acc: 0.6246\n",
      "Epoch 87/100\n",
      "3918/3918 [==============================] - 2s 388us/step - loss: 0.9199 - acc: 0.6192\n",
      "Epoch 88/100\n",
      "3918/3918 [==============================] - 1s 382us/step - loss: 0.9221 - acc: 0.6217\n",
      "Epoch 89/100\n",
      "3918/3918 [==============================] - 2s 385us/step - loss: 0.9207 - acc: 0.6235\n",
      "Epoch 90/100\n",
      "3918/3918 [==============================] - 2s 400us/step - loss: 0.9202 - acc: 0.6177\n",
      "Epoch 91/100\n",
      "3918/3918 [==============================] - 2s 417us/step - loss: 0.9247 - acc: 0.6263\n",
      "Epoch 92/100\n",
      "3918/3918 [==============================] - 1s 354us/step - loss: 0.9156 - acc: 0.6230\n",
      "Epoch 93/100\n",
      "3918/3918 [==============================] - 2s 387us/step - loss: 0.9211 - acc: 0.6248\n",
      "Epoch 94/100\n",
      "3918/3918 [==============================] - 2s 425us/step - loss: 0.9215 - acc: 0.6261\n",
      "Epoch 95/100\n",
      "3918/3918 [==============================] - 2s 412us/step - loss: 0.9220 - acc: 0.6149\n",
      "Epoch 96/100\n",
      "3918/3918 [==============================] - 2s 412us/step - loss: 0.9189 - acc: 0.6266\n",
      "Epoch 97/100\n",
      "3918/3918 [==============================] - 2s 426us/step - loss: 0.9190 - acc: 0.6197\n",
      "Epoch 98/100\n",
      "3918/3918 [==============================] - 2s 426us/step - loss: 0.9218 - acc: 0.6205\n",
      "Epoch 99/100\n",
      "3918/3918 [==============================] - 1s 358us/step - loss: 0.9168 - acc: 0.6248\n",
      "Epoch 100/100\n",
      "3918/3918 [==============================] - 1s 378us/step - loss: 0.9126 - acc: 0.6228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238914627f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier = Sequential()\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "# input_dim: number of independent var\n",
    "#classifier.add(Dense(output_dim = 6,init = 'uniform', activation = 'relu'))\n",
    "\n",
    "#adding layers with keras 2.0\n",
    "model = Sequential()\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=7))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# \n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train_white, y_train_white, batch_size = 5, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing predictions. if y_predict > 0.7 == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test_white)\n",
    "y_test_white = y_test_white.astype(float)\n",
    "y_predict = y_predict\n",
    "y_predict = y_predict > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5,   0,   3,   1,   0,   0],\n",
       "       [ 23,   0,  24,   4,   0,   0],\n",
       "       [201,   0,  64,  30,   0,   0],\n",
       "       [328,   0,  19,  62,   0,   0],\n",
       "       [161,   0,   0,  22,   0,   0],\n",
       "       [ 29,   0,   0,   4,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import argmax\n",
    "cf = confusion_matrix(y_test_white.values.argmax(axis=1), y_predict.argmax(axis=1))\n",
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy = accuracy_score(y_test_white, y_predict)\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not accurate. \n",
    "Improving the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  \"\"\"\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  \n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  \n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3918/3918 [==============================] - 7s 2ms/step - loss: 1.4759 - acc: 0.4372\n",
      "Epoch 2/100\n",
      "3918/3918 [==============================] - 4s 985us/step - loss: 1.3068 - acc: 0.4413\n",
      "Epoch 3/100\n",
      "3918/3918 [==============================] - 4s 994us/step - loss: 1.2980 - acc: 0.4461\n",
      "Epoch 4/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2917 - acc: 0.4538\n",
      "Epoch 5/100\n",
      "3918/3918 [==============================] - 5s 1ms/step - loss: 1.2883 - acc: 0.4558\n",
      "Epoch 6/100\n",
      "3918/3918 [==============================] - 4s 988us/step - loss: 1.2856 - acc: 0.4574\n",
      "Epoch 7/100\n",
      "3918/3918 [==============================] - 4s 984us/step - loss: 1.2873 - acc: 0.4558\n",
      "Epoch 8/100\n",
      "3918/3918 [==============================] - 4s 992us/step - loss: 1.2836 - acc: 0.4561\n",
      "Epoch 9/100\n",
      "3918/3918 [==============================] - 4s 999us/step - loss: 1.2843 - acc: 0.4553\n",
      "Epoch 10/100\n",
      "3918/3918 [==============================] - 4s 991us/step - loss: 1.2796 - acc: 0.4569\n",
      "Epoch 11/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2808 - acc: 0.4566\n",
      "Epoch 12/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2812 - acc: 0.4566\n",
      "Epoch 13/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2777 - acc: 0.4566\n",
      "Epoch 14/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2812 - acc: 0.4566\n",
      "Epoch 15/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2795 - acc: 0.4566\n",
      "Epoch 16/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2796 - acc: 0.4566\n",
      "Epoch 17/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2770 - acc: 0.4566\n",
      "Epoch 18/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2788 - acc: 0.4566\n",
      "Epoch 19/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2791 - acc: 0.4566\n",
      "Epoch 20/100\n",
      "3918/3918 [==============================] - 5s 1ms/step - loss: 1.2778 - acc: 0.4566\n",
      "Epoch 21/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2746 - acc: 0.4566\n",
      "Epoch 22/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2756 - acc: 0.4566\n",
      "Epoch 23/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2773 - acc: 0.4566\n",
      "Epoch 24/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2737 - acc: 0.4566\n",
      "Epoch 25/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2774 - acc: 0.4566\n",
      "Epoch 26/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2773 - acc: 0.4566\n",
      "Epoch 27/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2764 - acc: 0.4566\n",
      "Epoch 28/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2758 - acc: 0.4566\n",
      "Epoch 29/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2755 - acc: 0.4566\n",
      "Epoch 30/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2739 - acc: 0.4566\n",
      "Epoch 31/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2763 - acc: 0.4566\n",
      "Epoch 32/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2746 - acc: 0.4566\n",
      "Epoch 33/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2773 - acc: 0.4566\n",
      "Epoch 34/100\n",
      "3918/3918 [==============================] - 5s 1ms/step - loss: 1.2744 - acc: 0.4566\n",
      "Epoch 35/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2755 - acc: 0.4566\n",
      "Epoch 36/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2743 - acc: 0.4566\n",
      "Epoch 37/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2759 - acc: 0.4566\n",
      "Epoch 38/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2764 - acc: 0.4566\n",
      "Epoch 39/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2752 - acc: 0.4566\n",
      "Epoch 40/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2761 - acc: 0.4566\n",
      "Epoch 41/100\n",
      "3918/3918 [==============================] - 4s 968us/step - loss: 1.2765 - acc: 0.4566\n",
      "Epoch 42/100\n",
      "3918/3918 [==============================] - 4s 974us/step - loss: 1.2764 - acc: 0.4566\n",
      "Epoch 43/100\n",
      "3918/3918 [==============================] - 4s 975us/step - loss: 1.2752 - acc: 0.4566\n",
      "Epoch 44/100\n",
      "3918/3918 [==============================] - 4s 975us/step - loss: 1.2743 - acc: 0.4566\n",
      "Epoch 45/100\n",
      "3918/3918 [==============================] - 4s 978us/step - loss: 1.2756 - acc: 0.4566\n",
      "Epoch 46/100\n",
      "3918/3918 [==============================] - 4s 976us/step - loss: 1.2728 - acc: 0.4566\n",
      "Epoch 47/100\n",
      "3918/3918 [==============================] - 4s 981us/step - loss: 1.2745 - acc: 0.4566\n",
      "Epoch 48/100\n",
      "3918/3918 [==============================] - 4s 980us/step - loss: 1.2742 - acc: 0.4566\n",
      "Epoch 49/100\n",
      "3918/3918 [==============================] - 5s 1ms/step - loss: 1.2758 - acc: 0.4566\n",
      "Epoch 50/100\n",
      "3918/3918 [==============================] - 4s 971us/step - loss: 1.2740 - acc: 0.4566\n",
      "Epoch 51/100\n",
      "3918/3918 [==============================] - 4s 973us/step - loss: 1.2751 - acc: 0.4566\n",
      "Epoch 52/100\n",
      "3918/3918 [==============================] - 4s 981us/step - loss: 1.2740 - acc: 0.4566\n",
      "Epoch 53/100\n",
      "3918/3918 [==============================] - 4s 985us/step - loss: 1.2759 - acc: 0.4566\n",
      "Epoch 54/100\n",
      "3918/3918 [==============================] - 4s 989us/step - loss: 1.2752 - acc: 0.4566\n",
      "Epoch 55/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2737 - acc: 0.4566\n",
      "Epoch 56/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2736 - acc: 0.4566\n",
      "Epoch 57/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2748 - acc: 0.4566\n",
      "Epoch 58/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2748 - acc: 0.4566\n",
      "Epoch 59/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2749 - acc: 0.4566\n",
      "Epoch 60/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2742 - acc: 0.4566\n",
      "Epoch 61/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2751 - acc: 0.4566\n",
      "Epoch 62/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2733 - acc: 0.4566\n",
      "Epoch 63/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2743 - acc: 0.4566\n",
      "Epoch 64/100\n",
      "3918/3918 [==============================] - 5s 1ms/step - loss: 1.2743 - acc: 0.4566\n",
      "Epoch 65/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2737 - acc: 0.4566\n",
      "Epoch 66/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2738 - acc: 0.4566\n",
      "Epoch 67/100\n",
      "3918/3918 [==============================] - 4s 984us/step - loss: 1.2735 - acc: 0.4566\n",
      "Epoch 68/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2736 - acc: 0.4566\n",
      "Epoch 69/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2749 - acc: 0.4566\n",
      "Epoch 70/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2746 - acc: 0.4566\n",
      "Epoch 71/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2745 - acc: 0.4566\n",
      "Epoch 72/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2741 - acc: 0.4566\n",
      "Epoch 73/100\n",
      "3918/3918 [==============================] - 4s 998us/step - loss: 1.2729 - acc: 0.4566\n",
      "Epoch 74/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2749 - acc: 0.4566\n",
      "Epoch 75/100\n",
      "3918/3918 [==============================] - 4s 969us/step - loss: 1.2737 - acc: 0.4566\n",
      "Epoch 76/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2748 - acc: 0.4566\n",
      "Epoch 77/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2743 - acc: 0.4566\n",
      "Epoch 78/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2736 - acc: 0.4566\n",
      "Epoch 79/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2747 - acc: 0.4566\n",
      "Epoch 80/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2732 - acc: 0.4566\n",
      "Epoch 81/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2744 - acc: 0.4566\n",
      "Epoch 82/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2740 - acc: 0.4566\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3918/3918 [==============================] - 4s 967us/step - loss: 1.2737 - acc: 0.4566\n",
      "Epoch 84/100\n",
      "3918/3918 [==============================] - 4s 961us/step - loss: 1.2737 - acc: 0.4566\n",
      "Epoch 85/100\n",
      "3918/3918 [==============================] - 4s 955us/step - loss: 1.2733 - acc: 0.4566\n",
      "Epoch 86/100\n",
      "3918/3918 [==============================] - 4s 940us/step - loss: 1.2744 - acc: 0.4566\n",
      "Epoch 87/100\n",
      "3918/3918 [==============================] - 4s 1ms/step - loss: 1.2741 - acc: 0.4566\n",
      "Epoch 88/100\n",
      "3918/3918 [==============================] - 4s 897us/step - loss: 1.2745 - acc: 0.4566\n",
      "Epoch 89/100\n",
      "3918/3918 [==============================] - 3s 883us/step - loss: 1.2740 - acc: 0.4566\n",
      "Epoch 90/100\n",
      "3918/3918 [==============================] - 3s 872us/step - loss: 1.2741 - acc: 0.4566\n",
      "Epoch 91/100\n",
      "3918/3918 [==============================] - 3s 880us/step - loss: 1.2738 - acc: 0.4566\n",
      "Epoch 92/100\n",
      "3918/3918 [==============================] - 3s 856us/step - loss: 1.2731 - acc: 0.4566\n",
      "Epoch 93/100\n",
      "3918/3918 [==============================] - 3s 873us/step - loss: 1.2744 - acc: 0.4566\n",
      "Epoch 94/100\n",
      "3918/3918 [==============================] - 3s 858us/step - loss: 1.2733 - acc: 0.4566\n",
      "Epoch 95/100\n",
      "3918/3918 [==============================] - 4s 988us/step - loss: 1.2730 - acc: 0.4566\n",
      "Epoch 96/100\n",
      "3918/3918 [==============================] - 3s 867us/step - loss: 1.2743 - acc: 0.4566\n",
      "Epoch 97/100\n",
      "3918/3918 [==============================] - 3s 865us/step - loss: 1.2746 - acc: 0.4566\n",
      "Epoch 98/100\n",
      "3918/3918 [==============================] - 3s 882us/step - loss: 1.2741 - acc: 0.4566\n",
      "Epoch 99/100\n",
      "3918/3918 [==============================] - 3s 887us/step - loss: 1.2734 - acc: 0.4566\n",
      "Epoch 100/100\n",
      "3918/3918 [==============================] - 3s 883us/step - loss: 1.2739 - acc: 0.4566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2389d4b5358>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "odel = Sequential()\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=7))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=11, input_dim=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(p = 0.2))\n",
    "model.add(Dense(units=7))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train_white, y_train_white, batch_size = 5, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test_white)\n",
    "y_test_white = y_test_white.astype(float)\n",
    "y_predict = y_predict\n",
    "y_predict = y_predict > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,   0,   0,   0,   0,   0],\n",
       "       [ 51,   0,   0,   0,   0,   0],\n",
       "       [295,   0,   0,   0,   0,   0],\n",
       "       [409,   0,   0,   0,   0,   0],\n",
       "       [183,   0,   0,   0,   0,   0],\n",
       "       [ 33,   0,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cf = confusion_matrix(y_test_white.values.argmax(axis=1), y_predict.argmax(axis=1))\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy was reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "xclas = XGBClassifier()  # for classifier\n",
    "xclas.fit(X_train_white, y_train_white)\n",
    "y_pred = xclas.predict(X_test_white)\n",
    "\n",
    "cross_val_score(xclas, X_train_white, y_train_white)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_white, y_pred)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for Windows, xgboost it is avaliable only in anaconda:\n",
    " \n",
    " \n",
    " Cross_val_score:  array([0.59770992, 0.55708812, 0.58940906])\n",
    " \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conslusion \n",
    "\n",
    "In this analysis, the two models that performed the best were the KNN and the KernelSVC. Those models achieved about 0.65 of accuracy on the test set. The accuracy for the training models was close to 1.0 which is an indicative of overfitting.\n",
    "Feature extraction did not improve the accuracy of the models.\n",
    "In the research paper. They manage to have an accuracy of 0.868 using the Fuzzy inductive Reasoning methodology, an absolute error tolerance of 1.0 and the discretization of the input variables. Their results vary greatly. For the SVM model, they vary from 0.503 to 0.868 (0.25 to 1.0 absolute error tolerance).\n",
    "In contrast to the research paper, the discretization of the input variables into two categories did not increased accuracy, on the contrary, it significantly reduced it.\n",
    "Apparently, ANN and Xgboost are not better that KNN and SVC models.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "What is Fuzzy inductive reasoning(FIR)?\n",
    "\n",
    "What is the absolute error tolerance T that is used with FIR?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
